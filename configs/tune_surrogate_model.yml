tuning_method: "tune_surrogate_model"
n_trials: 100
direction: "maximize"
path_to_optuna_db: "sqlite:///optuna_fedot_pipelines_and_openml_meta_features2.db"

batch_size: 16

num_dataloader_workers: 32

model:
  name: "RankingPipelineDatasetSurrogateModel"
  model_parameters:
    in_size: null  # The parameter is inferred
    num_class: 1
    d_model: [32, 128, 32]
    dim_feedforward: null  # The parameter is inferred
    dropout: [0.2, 0.6]
    num_heads: [2, 8, 2]
    num_layers: [2,  4]
    # batch_norm: [True, False]
    # Not working with current settings: "gin", "khopgnn", "rwgnn", "pna4", "gine", "mpnn"
    gnn_type: ["graph", "graphsage", "gcn"]
    k_hop: [1, 3]
    se: "gnn"
    deg: null  # The parameter is inferred
    global_pool: ["mean", "add", "cls"]
    use_edge_attr: False
    pipe_encoder_type: ["graph_transformer", "simple_graph_encoder"]
  lr: [0.0001, 0.01]
  weight_decay: [0.00001, 0.0001]
  

dataset_params:
  root_path: "./data/openml_meta_features_and_fedot_pipelines/all"

trainer:
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  max_epochs: 100
  accelerator: "cpu"
  devices: "auto"

tensorboard_logger: null
tensorboard_logger:
  save_dir: "./experiments/tune_surrogate_model"
  name: "hyperparameter_tuning"

model_checkpoint_callback:
  save_top_k: 1
  monitor: "val_ndcg"
  mode: "max"
  save_last: False
  every_n_epochs: 1

early_stopping_callback:
  monitor: "val_ndcg"
  mode: "max"
  patience: 2